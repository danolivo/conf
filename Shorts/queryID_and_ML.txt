Технология Query ID открывает путь применению ML-методов в управлении СУБД?

А кто из вас пытался применять методы машинного обучения для автоматизации тюнинга СУБД?
Мы, подразделение оптимизации в компании Postgres Professional, начиная с 2016 года пробуем делать это регулярно: адаптивный оптимизатор запросов [1], фризер планов [2] и перепланировщик [3] тому хорошие примеры.
Основная проблема использования ML внутри СУБД - классификация запросов. Быстро и с хорошей достоверностью отнести запрос к некоторому классу с заранее заданными свойствами ранее было недоступно. Однако с недавнего времени в PostgreSQL появился параметр Query ID, обладающий двумя замечательными свойствами:
1. Он генерируется по дереву плана запроса
2. Формирование данного 64-битного хэша происходит с минимальными накладными расходами.
3. Код генератора Query ID является автогенерируемым по исходному коду СУБД. 
Пункт 1 гарантирует нам независимость от синтаксических особенностей запроса: разделители, регистр записи и т.д. Также, он позволяет учесть правила перезаписи запросов, которые могут изменяться (например изменение определения VIEW) и менять семантическое наполнение запроса.
Пункт 3 позволяет, используя достаточно не инвазивную процедуру, на этапе подготовки дистрибутива создать один или более генераторов Query ID и использовать их в расширениях для различных целей.
Уже в текущей имплементации Query ID позволяет с большой точностью отделять один запрос от другого, позволяя расширению pg_stat_statements собирать статистику выполнения различных запросов. Однако он также и позволяет нам в расширении sr_plan [2], которое сопоставляет входящему запросу “замороженный” план, избегая повторной процедуры оптимизации сначала находи.ть небольшое множество кандидатов и потом доказывать соответствие плана в кэше входящему запросу методом сопоставления деревьв запроса.
Несложно представить себе дальнейшее расширение области применения этого параметра. Например, можно сделать Query ID устойчивым к перестановке порядка следования источников в условии FROM … или выражений в условии WHERE, сделав его более универсальным. Или исключить из хэша значения констант.
В последнем случае мы получаем отличный классификатор, который позволяет анализировать каждый запрос в отдельности и выбирать паттерны его применения, находить часто меняющиеся константы и константы, значимые для времени выполнения запроса или ошибки оценки кардинальности. Таким образом, это открывает путь для разработки алгоритмов автоматического поиска  обобщающих параметризаций запросов, которые следует оптимизировать и, возможно, закреплять в кэше планы таких запросов. Или запоминать набор планов одного запроса и выдавать один из них, который является наиболее оптимальным в какое-то определённое время года, месяц или время суток. Имея такой классификатор, возможности для применения методов машинного обучения для управления поведением СУБД кардинально расширяются …
А в вашей СУБД есть такой инструмент?

[1] https://github.com/postgrespro/aqo
[2] https://postgrespro.com/docs/enterprise/15/sr-plan
[3] https://pgconf.ru/en/talk/1589471


Does Query ID technology give PostgreSQL developers a tool to use ML methods in DBMS management?

How many of you have tried using a machine-learning approach to self-manage DBMS instances?

We, the optimization division at Postgres Professional, have been trying to develop such codes regularly since 2016: the adaptive query optimizer [1], plan freezer [2], and replanning feature [3] are pretty good examples.
The main problem of using ML inside a DBMS is query classification. It was previously impossible to assign an incoming query to a particular class (with predefined properties) quickly and with good reliability. However, PostgreSQL recently introduced the Query ID parameter, which has two remarkable properties:
1. It is generated from the query parse tree
2. This 64-bit hash is generated with petty overhead.
3. The Query ID generator code is auto-generated from the DBMS source code.
Point 1 guarantees us independence from the syntactic features of the query: space delimiters, lower or capital case, etc. Also, it uses an already rewritten parse tree and avoids the problem of rewriting rules (for example, altering the VIEW definition), which can totally change the semantic content of the query.
Point 3 allows creating one or more Query ID generators and using them in extensions for various purposes, using a relatively noninvasive procedure at the binaries preparation stage.
Even in the current implementation, Query ID allows you to separate one query from another with good enough accuracy, allowing the pg_stat_statements extension to collect statistics on the execution of various requests. However, it also allows us in the sr_plan extension [2], which match a "frozen" plan to an incoming query, avoiding a repeated optimization procedure, first finding a small set of candidates and then proving the compliance of the plan in the cache to the incoming query using the query tree matching technique.
It is not difficult to imagine further expansion of the scope of this parameter. For example, you can make the Query ID resistant to rearranging the order of sources in the "FROM" clause or expressions in the "WHERE" clause, making it more universal. Or exclude constant values from the hash.
In the latter case, we get an excellent classifier that allows us to analyze each query separately and identify the patterns of its application, find frequently changing constants and constants that are significant for the query execution time or cardinality estimation errors. Thus, this opens the way for the development of algorithms for automatically finding generalized query parameterizations that should be optimized and cache the plans for such queries. Or remember a set of plans for one query and return one of them, which is the most optimal at a specific time of the year, month or day. Having such a classifier as Query ID, the possibilities for using machine learning methods to control the behaviour of a DBMS are expanding drastically ...
Does your DBMS have such a tool?
