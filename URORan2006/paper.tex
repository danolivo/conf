\documentclass[11pt]{article}
\usepackage{amsmath}           % Разместить сразу после 1 команды(для MiKTeX20e),
                                % если используете возможности пакета
\usepackage[cp866]{inputenc}    % для DOS (обязательно!)
\usepackage[english,russian]{babel}     % Переносы через Babel (обязательно!)
\usepackage{parall2006}           % Стилевой пакет сборника
\usepackage{cite}

\usepackage{amsfonts,amssymb}  % Если есть необходимость выбора
                                % математических алфавитов
                                % \mathbb{} - amsfonts.sty
                                % \mathfrak{} - eufrak.sty, amsfonts.sty
                                % символы шрифта Euler - amssymb.sty
\usepackage{latexsym}          % Подключение шрифтов LaTeX2.09
                               % (если есть необходимость)
\usepackage{graphicx}          % для включения графических изображений
\usepackage{srcltx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\Leftclt}{П.\,С.\,Костенецкий, А.\,В.\,Лепихов, Л.\,Б.\,Соколинский}
\newcommand{\Rightclt}{Параллельные технологии}
\newcommand{\UDK}{681.3.06}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\hyphenation{авто-ма-ти-чес-кой адап-тера адекват-ность}
\hyphenation{алго-рит-ми-чес-ко-го ана-ли-ти-чес-ко-го архи-тек-ту-ры}
\hyphenation{алго-рит-ма алго-рит-мов алго-рит-мы алго-ритм}
\hyphenation{безыте-ра-ци-он-ные быстрая}
\hyphenation{взаимо-дей-ству-ют взаимо-дей-ствую-щих}
\hyphenation{ви-зуа-ли-за-ция ви-зуа-ли-за-ции внут-рен-них воз-мож-нос-ти}
\hyphenation{воз-можность}
\hyphenation{воз-ни-каю-щей воз-ни-каю-щие воз-раста вообще всегда}
\hyphenation{вы-чис-ли-те-ле вы-чис-ля-ет-ся вы-чис-ле-ния вы-чис-ли-те-ля}
\hyphenation{вы-чис-ля-ет вы-чис-ле-ний}
\hyphenation{Вы-чис-ли-тель-ных вы-чис-ли-тель-ной вы-чис-ле-ний вы-чис-ле-ния}
\hyphenation{гео-фи-зи-чес-ким гисто-грам-мы гра-фи-чес-кое}
\hyphenation{де-шев-ле Дирих-ле до-став-ляю-ще-го до-став-ляю-щее}
\hyphenation{иерар-хи-че-ские иерар-хи-че-ской}
\hyphenation{изобра-же-ний интер-пре-та-ции итера-ци-он-но-го итера-ци-он-ных}
\hyphenation{Каж-дая каж-дая каж-дой каж-дый качествен-ной кода компо-нент}
\hyphenation{конт-рас-та ко-раб-лей кос-ми-чес-ких}
\hyphenation{макси-маль-ных ма-те-ма-ти-чес-ким матри-ца моду-лей}
\hyphenation{моде-ли-ро-ва-ние моде-ли}
\hyphenation{между ме-шаю-щих моде-ли-рую-щей моде-ли-рую-щую мышле-ние}
\hyphenation{наблюде-ние наблюде-ния}
\hyphenation{напи-сан-ной на-прав-ле-ни-ях науч-ных необ-ходи-мос-тью}
\hyphenation{не-пере-се-каю-щих-ся не-суще-ствен-ную}
\hyphenation{об-лас-ти обуче-ния объеди-не-нии объеди-не-ния}
\hyphenation{объек-та объек-те объек-тов ожив-ле-ние опти-чес-ко-го ор-га-ни-зо-вать}
\hyphenation{отобра-же-ние отобра-же-ни-ем отобра-же-ния}
\hyphenation{парал-лель-но-го парал-лель-ных парал-лель-ный парал-ле-лиз-ма}
\hyphenation{парал-лель-ной парал-лель-ны-ми парал-лель-ным}
\hyphenation{пара-мет-ра пара-мет-ру перед}
\hyphenation{по-верх-нос-ти}
\hyphenation{раз-ре-ше-ни-ем рас-смат-ри-вать-ся реб-ра сов-пада-ет}
\hyphenation{под-об-лас-тях позво-ля-ет поз-во-ляю-щий поис-ка пока}
\hyphenation{по-сле-до-ва-тель-нос-ти по-сле-до-ва-тель-нос-тей}
\hyphenation{по-стоян-ства по-строе-ние по-строе-ния предва-ри-тель-ного}
\hyphenation{пред-став-лен пред-став-ле-ние пред-став-ле-ния пред-став-ля-ет}
\hyphenation{пред-став-ле-ний пред-став-ля-ют-ся преду-смотре-ны}
\hyphenation{пред-шест-вую-ще-го предыду-ще-го предысто-рия проблем}
%\hyphenation{програм-мы программ-ным программ-ны-ми програм-мой программ}
%\hyphenation{програм-ма програм-ме програм-ми-ро-ва-ния програм-мист}
\hyphenation{программ-но-го}
\hyphenation{простых про-цедур публи-ка-ций}
\hyphenation{рас-парал-ле-ли-ва-ние рас-парал-ле-ли-ва-ния}
\hyphenation{рас-парал-ле-ли-ва-ют-ся рас-смат-ри-ва-ет-ся}
\hyphenation{рас-смот-ре-ния реали-за-ци-ей}
\hyphenation{сгущаю-щих-ся сис-тем сис-те-ма сис-те-мы сис-те-му сис-те-ме}
\hyphenation{сис-тем-ное}
\hyphenation{слож-нос-ти сово-куп-нос-ти созда-ва-е-мой}
\hyphenation{со-став-лен-ные со-став-ляю-щую}
\hyphenation{со-став-ляю-щие собран-ная со-стоя-ни-ем со-стоя-щим}
\hyphenation{спе-циа-лис-тов спе-циаль-ный статьи}
\hyphenation{сте-пенью степень}
\hyphenation{табл теоре-мы теп-ло-ви-зи-он-но-го точ-нос-ти точ-ностью тради-ци-он-ной}
\hyphenation{уве-дом-ле-ние уничто-же-ние управ-ле-ние управ-ле-ния управ-ля-емый}
\hyphenation{уста-нав-лива-ет-ся}
\hyphenation{функци-о-на-лу}
\hyphenation{целью центре час-ти часто чело-ве-чес-ко-му четверть}
\hyphenation{число числа числе числу числах число-вых}
\hyphenation{Швар-ца эллип-ти-чес-кие эллип-ти-чес-ко-го эф-фек-тив-нос-ти}
\setcounter{page}{42}            % Команда обязательна, хотя номер уточняется
                                % позднее
% Вписываем название статьи и фамилии авторов (следите за
% шрифтом и пробелами!). Ссылку на гранты помещаем в сноске
% к названию статьи.
% Для установки полужирного шрифта для формул можно воспользоваться
% следующей конструкцией \mbox{$\mathrm{A B C s}$}.
% Используем окружение Titul.

%-----------------------------------------------------------------------
\ttl
{НЕКОТОРЫЕ АСПЕКТЫ ОРГАНИЗАЦИИ ПАРАЛЛЕЛЬНЫХ СИСТЕМ БАЗ ДАННЫХ
ДЛЯ МУЛЬТИПРОЦЕССОРОВ С ИЕРАРХИЧЕСКОЙ АРХИТЕКТУРОЙ\protect\footnote{Работа выполнена при финансовой поддержке
Российского фонда фундаментальных исследований (проект 06-07-89148)
и Южно-Уральского государственного университета (проект 2006112).}}
{П.\,С.~Костенецкий, А.\,В.~Лепихов, Л.\,Б.~Соколинский}

\renewcommand{\theequation}{\arabic{equation}}
%\newcommand{\proof}{\par\mbox{Д о к а з а т е л ь с т в о.}\hspace{2mm}}
\newcommand{\proof}{\mbox{Д о к а з а т е л ь с т в о.}\hspace{2mm}}
\newtheorem{teo}{\hspace*{-1\parindent}Теорема}
\newcommand{\eproof}{
\mbox{Т е о р е м а\ \ д о к а з а н а.}\hspace{2mm}}
\section*{Введение}

\indent

%\par\noindent
В настоящее время все большее распространение получают иерархические
многопроцессорные архитектуры. В многопроцессорной системе с иерархической
архитектурой процессорные устройства, память, диски и проч. связываются друг с
другом в соответствии с некоторой иерархией. На первом уровне иерархии находятся
процессорные ядра, размещенные на одном кристалле. На втором уровне находятся
многоядерные процессоры, объединенные в многопроцессорные модули с общей
памятью (SMP). На третьем уровне SMP-модули объединяются в кластер с помощью
высокоскоростной соединительной сети. Четвертый уровень представляют
Grid-системы, включающие в себя несколько кластеров. Корпоративные Grid-системы
могут объединяться в кооперативные Grid-объединения на базе Интернет. И так далее.

{\baselineskip=0.95\baselineskip
Одним из наиболее важных приложений для многопроцессорных систем являются
параллельные системы баз данных, способные хранить и обрабатывать петабайты
данных~\cite{B_Gray05}.
Параллельным системам баз данных
посвящено большое
количество работ, обзор которых можно найти в~\cite{B_Graefe93}. Однако проблематика
систем баз данных с иерархической многопроцессорной архитектурой  была исследована мало.

\parВ статье рассматриваются вопросы организации параллельных систем баз данных,
ориентированной на эффективное использование многопроцессорных иерархий. Здесь
мы выделяем следующие три аспекта: моделирование иерархических архитектур,
распределение данных и балансировка загрузки, параллельная организация
выполнения запросов.

\parИерархические архитектуры порождают большое
%количество
число
различных классов конфигураций. Некоторая классификация таких
архитектур дана в~\cite{B_Sok04}. Исследование подобных архитектур затруднено,
так как практическое
конструирование мультипроцессоров требует больших финансовых затрат, связанных с
приобретением и реконфигурацией дорогостоящего оборудования.
% !!! -+ В соответствии с этим, актуальной является
Как следствие, актуальной становится задача разработки моделей представления
многопроцессорных систем баз данных, которые позволяли бы исследовать различные
многопроцессорные конфигурации без их аппаратной реализации.
Моделирование всех одноуровневых архитектур для оперативной обработки транзакций
было выполнено Стоунбрейкером и Бхайдом~\cite{B_Bhide88a,B_Bhide88b}. В работах~\cite{B_Bouganim96, B_Xu97} моделируются
некоторые классы двухуровневых конфигураций, однако в общем виде
многопроцессорные иерархические конфигурации не исследовались. В связи с этим возникает проблема выбора оптимального класса конфигураций для определенного класса приложений баз
данных. В данной работе описана модель DMM (Database Multiprocessor Model),
позволяющая моделировать и исследовать произвольные многопроцессорные
иерархические конфигурации в контексте приложений класса OLTP~\cite{B_DeWitt95}.
}

\parПроблеме распределения данных и связанной с ней проблеме балансировки загрузки
в параллельных системах баз данных без совместного использования ресурсов
посвящено большое количество работ (см., например,~\cite{B_Bitton88, B_Mehta97,B_Chen91, B_Williams98}), однако данная
проблематика в контексте иерархических многопроцессорных систем до настоящего
времени практически не исследовалась. В статье предлагается стратегия размещения
данных для иерархических вычислительных систем и алгоритм балансировки загрузки,
основанный на методе частичного зеркалирования. Алгоритм используется
при обработке запросов в прототипе параллельной системы баз данных ``Омега'' \cite{B_Proto}.

Еще одной серьезной проблемой является построение механизма распараллеливания запросов, масштабируемого вверх по иерархии. В данной статье описана новая модель распараллеливания запросов, ориентированная на иерархические многопроцессорные архитектуры. Предложенная модель позволяет выполнять на мультипроцессорной системе много различных запросов одновременно. Каждый из этих запросов может быть автоматически распараллелен на любом уровне многопроцессорной иерархии. Это достигается путем введения специального оператора обмена, инкапсулирующего в себе все механизмы, необходимые для реализации внутриоперационного параллелизма.

Статья организована следующим образом. В разделе\,\ref{sec:modeling}
приводится описание DMM модели. Представлены модели аппаратной платформы и
операционной среды, приведены стоимостная модель и модель транзакций. В
разделе\,\ref{sec:strategy}
% !!!! -w приводится описание стратегии размещения данных и алгоритма
рассматриваются стратегия размещения данных и алгоритм
балансировки загрузки в иерархической вычислительной системе.
Вводится формальное определение симметричной многопроцессорной иерархии.
Описывается механизм репликации данных на основе сегментов. Доказываются
теоремы, дающие оценки для суммарного размера реплик и трудоемкости
формирования реплик при отсутствии помех. Представлен алгоритм балансировки
загрузки, основанный на    описанном    механизме репликации. В
разделе\,\ref{sec:QueryPr}
% !!! -w описывается
обсуждается
организация параллельной    обработки
запросов применительно к иерархическим многопроцессорным системам баз
данных с использованием     разработанного     нами алгоритма балансировки
загрузки. В разделе\,\ref{sec:conclusion} суммируются полученные результаты
и обсуждаются направления дальнейших исследований.

\section{Моделирование иерархических архитектур}\label{sec:modeling}

\indent\vspace*{-3ex}

%\noindent
Данный раздел посвящен моделированию многопроцессорных
иерархических конфигураций. Предлагается новая модель \emph{DMM (Database
Multiprocessor Model)}, позволяющая моделировать и исследовать произвольные
многопроцессорные иерархические конфигурации в контексте приложений класса
OLTP. Модель DMM включает в себя
% !!!! -w модель аппаратного обеспечения, модель программного обеспечения и
модели аппаратного и программного обеспечения, а также
стоимостную модель.

\subsection{Модель аппаратной платформы}\label{sec:hardwaremodel}

\indent\vspace*{-3.5ex}

%\noindent
Аппаратное обеспечение параллельной системы баз данных представляется в
виде \emph{DM}-дерева. \emph{DM-дерево}~--- это ориентированное дерево \cite{B_Knuth3},
узлы которого относятся к одному из трех классов:

\renewcommand{\labelenumi}{(\theenumi)}
{\parskip=-1ex
\begin{enumerate}
\parskip=-1pt
\itemпроцессорные модули;
\itemдисковые модули;
\itemмодули сетевых концентраторов.
\end{enumerate}
}

% !!! ! думается, что поток данных может быть и между процессорным модулем
% !!! и дисковым, но такой дуги нет, т.е. дуга соответствует чему-то другому.
% *** Поток данных между процессором и диском осуществляется через родительский
% *** сетевой концентратор, который в этом случае ``символизирует'' системную шину.
\parДуги дерева соответствуют потокам данных. \emph{Процессорные модули}
являются абстрактным представлением реальных процессорных устройств.
\emph{Дисковые модули} представляют накопители на жестких магнитных дисках.
\emph{Модули сетевых концентраторов} используются для представления
произвольного \emph{интерконнекта}, соединяющего различные процессорные и
дисковые устройства. В качестве интерконнекта могут фигурировать как
отдельные сетевые устройства (коммутатор, концентратор и др.), так и
системная шина, соединяющая процессор с периферийными устройствами. Модель
DMM не предусматривает представление модулей оперативной памяти, так как в
задачах OLTP время взаимодействия процессоров и оперативной памяти
несоизмеримо меньше времени обменов данными с внешними устройствами.

\begin{figure}[!ht]
\includegraphics{images/DMtree.eps}\vspace*{-6mm}
\begin{flushleft}
\caption{Пример $DM$-дерева.}
\label{fig:DMtree}
\end{flushleft}\vspace*{-7mm}

\end{figure}

На структуру $DM$-дерева накладываются следующие ограничения:

\renewcommand{\labelenumi}{(\theenumi)}
{
\topskip=-1ex
\begin{enumerate}
\parskip=-1ex
\itemкорнем $DM$-дерева может быть только модуль сетевого концентратора;
\itemдисковые и процессорные модули не могут иметь дочерних узлов, т.\,е. они
всегда являются листьями $DM$-дерева.

% *** \itemмодуль сетевого концентратора не может иметь менее двух дочерних узлов.
% Нужно ли 3-е ограничение?

\end{enumerate}
}

\subsection{Модель операционной среды}\label{sec:osmodel}

%\par\noindent
В рамках модели DMM наименьшей неделимой единицей обработки
данных является \emph{пакет}.
% *** Убрал:  В реальной системе баз данных в качестве пакета может фигурировать
% *** один или несколько кортежей.
Мы предполагаем, что все пакеты одного размера и имеют заголовок.
Заголовок пакета включает в себя адреса отправителя и получателя, а также другую
вспомогательную информацию. Передача пакета может соответствовать передаче
одного или нескольких кортежей в реальной системе баз данных.

\parПоскольку рассматриваются только OLTP приложения, мы можем
пренебречь накладными расходами на обмены между двумя процессорами через
общую оперативную память и затратами на обработку данных внутри
процессоров. В модели DMM любой процессорный модуль может обмениваться
данными с любым дисковым модулем. С каждым дисковым модулем и модулем
сетевого концентратора в модели DMM ассоциируется \emph{очередь}, в которую
помещаются пересылаемые пакеты.

Модель DMM допускает асинхронный обмен пакетами в том смысле, что
процессорный модуль может инициализировать новый обмен, не дожидаясь
завершения предыдущего. Однако мы предполагаем, что процессорный модуль
может иметь в каждый момент не более $s_{r}$ незавершенных операций
чтения и $s_{w}$ незавершенных операций записи.

Время работы системы в модели DMM делится на дискретные промежутки,
называемые \emph{тактами}. Такт определяется как фиксированная
последовательность шагов, семантика которых будет определена ниже.

Пусть $\mathfrak{P}$ обозначает множество всех процессорных модулей
$DM$-дерева, $\mathfrak{D}$~--- множество всех дисковых модулей,
$\mathfrak{N}$~---
множество всех модулей сетевых концентраторов,
$\mathfrak{M}=\mathfrak{P}\cup\mathfrak{D}\cup\mathfrak{N}$~--- множество всех
узлов $DM$-дерева. Для произвольного $M\in \mathfrak{M}$ введем следующие
обозначения: $F(M)$~--- родительский модуль узла $M$, $T(M)$~--- поддерево с
корнем в вершине $M$.

\emph{\bf Процессорный модуль} $P\in \mathfrak{P}$ может инициировать
операции чтения и записи пакетов. Определим их семантику следующим образом.

% !!! ! Выделение адреса получателя неудачное, так как ранее так выделялись
% !!! ! вводимые термины.
% *** Я убрал выделение для ясности.

% !!! ! Более того, требуется какое-то пояснение того, почему в модели
% !!! ! время посылки пакетов с заказом на чтение к удаленному диску не
% !!! ! зависит от расстояния (количества узлов в DM-дереве) до диска,
% *** Потому, что в реальной параллельной СУБД никаких посылок с заказами
% *** на чтение не делается. Здесь это - просто механизм эмуляции работы ПСУБД.

\par\emph{Операция чтения}. Пусть процессорному модулю $P$ требуется прочитать
пакет $E$ с диска $D\in \mathfrak{D}$. Если процессор $P$ ранее
инициализировал $s_{r}$ ещё незавершенных операций чтения, то он переводится
в состояние ожидания. Если количество незавершенных операций чтения меньше $s_{r}$,
то в очередь диска $D$ помещается пакет $E$ с адресом получателя $\alpha(E)=P$
и адресом отправителя $\beta(E)=D$. На рис.\,\ref{fig:ReadOp} представлен
псевдокод данного алгоритма, где $r(P)$~--- количество незавершенных операций
чтения процессора $P$, $s_{r}$~--- максимальное допустимое число незавершенных
операций чтения.

\begin{figure}[!ht]
\begin{center}
\includegraphics{images/readop.eps}\vspace*{-6mm}
\begin{flushleft}
\caption{ Алгоритм чтения пакета процессорным модулем.}
\label{fig:ReadOp}
\end{flushleft}\vspace*{-10mm}
\end{center}
\end{figure}

\par\emph{Операция записи}. Пусть процессорному модулю $P$ требуется записать
пакет $E$ на диск $D\in \mathfrak{D}$. На рис.\,\ref{fig:WriteOp} представлен
псевдокод алгоритма, инициирующего запись.
Здесь $w(P)$~--- количество незавершенных операций записи процессора $P$, $s_{w}$~---
максимальное допустимое число незавершенных операций записи.

\begin{figure}[!ht]
\begin{center}
\includegraphics{images/writeop.eps}\vspace*{-6mm}
\begin{flushleft}
\caption{ Алгоритм записи пакета процессорным модулем.}
\label{fig:WriteOp}
\end{flushleft}\vspace*{-10mm}
\end{center}
\end{figure}


\begin{figure}[!ht]
\begin{center}
\includegraphics{images/hubpassop.eps}\vspace*{-6mm}
\begin{flushleft}
\caption{Алгоритм пересылки пакета сетевым концентратором.}
\label{fig:hpo}
\end{flushleft}\vspace*{-12mm}
\end{center}
\end{figure}

\emph{\bf Модуль сетевого концентратора} $N\in \mathfrak{N}$ осуществляет
перманентную передачу пакетов по соединительной сети, выполняя алгоритм,
изображенный на рис.\,\ref{fig:hpo}.
Здесь $E$~--- пакет, $\alpha(E)$~--- адресат пакета $E$, $T(N)$~--- поддерево с корнем $N$,
$F(N)$~--- родительский модуль узла $N$, $\mathfrak{P}$~--- множество процессорных
модулей, $r(P)$~--- количество незавершенных операций чтения процессора $P$,
$R(U)$~--- корень поддерева $U$.

\emph{\bf Дисковый модуль} $D\in \mathfrak{D}$ осуществляет перманентное чтение
и запись пакетов, выполняя алгоритм, изображенный на рис.\,\ref{fig:dpo},
где $\beta(E)$~--- отправитель пакета.

\begin{figure}[!ht]
\begin{center}
\includegraphics{images/diskpassop.eps}\vspace*{-6mm}
\begin{flushleft}
\caption{ Алгоритм пересылки пакета дисковым модулем.}
\label{fig:dpo}
\end{flushleft}\vspace*{-12mm}
\end{center}
\end{figure}

В модели DMM процесс обработки данных организуется в виде цикла,
выполняющего стандартную последовательность шагов, называемую \emph{тактом}.
Такт определяется как следующая последовательность действий:

\renewcommand{\labelenumi}{(\theenumi)}
{
\topskip=-2ex
\begin{enumerate}
\parskip=-1ex
\itemкаждый модуль сетевого концентратора обрабатывает все пакеты, ожидающие передачи;
\itemкаждый активный процессорный модуль выполняет одну операцию чтения или записи;
\itemкаждый дисковый модуль обрабатывает один пакет из своей очереди.
\end{enumerate}
}
% !!! ? Действительно ли, что если активный ПМ положил пакет на чтение
% !!! ? в очередь ДМ, то этот пакет будет сразу же перемещен в очередь МСК?
% *** Да именно так.

Очевидно, что в этом случае в очереди любого концентратора не может
одновременно находиться более $\vert \mathfrak{P} \vert+\vert
\mathfrak{D}\vert$ пакетов, а в очереди любого диска~--- более
$s_{r}s_{w}\vert \mathfrak{P} \vert$ пакетов.

\subsection{Стоимостная модель}\label{sec:costmodel}

%\noindent
С каждым модулем $M\in \mathfrak{M}$ связывается
\emph{коэффициент трудоемкости}
$h_{M}\in \mathbb{R},\ 1\leq h_{M}<+\infty\,.$
Так как время обработки процессором одного пакета для OLTP-приложений
приблизительно в
% !!! -+ $10^5-10^6$ раза быстрее,
$10^5-10^6$~раз меньше, чем время обмена с диском
или передачи по сети, то полагаем
\[
h_{p}=1,\ \forall P\in \mathfrak{P}\:.
\]
Так как модуль сетевого концентратора за один такт может передавать несколько пакетов,
то для каждого модуля сетевого концентратора $N\in \mathfrak{N}$ мы вводим функцию помех
\[
f_N (m_i^N ) = e^{\frac{{m_i^N }}
{{\delta _N }}}\:.
\]
Здесь $m_{i}^N$ обозначает число пакетов, проходящих через $N$ на $i$-м такте;
$\delta_N>1$~--- масштаби\-рую\-щий коэффициент. Таким образом, время,
требуемое модулю сетевого концентратора $N$ для выполнения $i$-го такта,\,
вычисляется по формуле
\[
t_i^N  = h_N f_N (m_i^N ),\qquad \forall N \in \mathfrak{N}\:.
\]

Общее время
работы системы, затраченное на обработку смеси транзакций (см. п.\,1.4)
в течении $k$ тактов,\, вычисляется по формуле
\[
t = \sum\limits_{i = 1}^k {\max (\mathop {\max }\limits_{N \in \mathfrak{N}} (t_i^N ),\mathop{\max}\limits_{D\in \mathfrak{D}}(h_D) )}\:.
\]



\subsection{Модель транзакций}\label{sec:transactionmodel}

%\noindent
Транзакция $Z$ моделируется путем задания двух групп процессов
$\rho$ и $\omega$: $Z=\{ \rho,\omega\}$. Группа $\rho$ включает в себя
\emph{читающие} процессы, группа $\omega$~--- \emph{пишущие} процессы. Процессы
абстрагируют операции чтения (записи), выполняемые при обработке транзакций.

Количество читающих процессов определяется количеством дисков, с которых
транзакция $Z$ производит чтение данных, по одному процессу на каждый диск.
Аналогичным образом, количество пишущих процессов определяется количеством
дисков, на которые выполняется запись при выполнении транзакции $Z$. При этом,
если один и тот же диск используется и для чтения, и для записи, то ему
сопоставляется два отдельных процесса~--- один пишущий и один читающий.

Модель DMM допускает выполнение на одном процессоре смеси параллельных
транзакций. При этом каждая транзакция $Z_{i}\ (i=1..k)$ представляется своей
собственной парой групп читающих и пишущих процессов: $Z_i=\{ \rho_i, \omega_i \}$.
Все множество процессов, моделирующих выполнение смеси транзакций, определяется
следующим образом:
\[
\Phi  = \bigcup\limits_{i = 1}^k {(\rho _i  \cup \omega _i )}\:.
\]

Для каждого процесса $\phi\in \Phi$ задается вероятность срабатывания $p_{\phi}$,
т.\,е. вероятность обращения к диску, ассоциированному с этим процессом.
В соответствии с этой вероятностью определяется \emph{функция активности} $g(p_\phi)$.
Функция активности $g(p_\phi)=G$ представляет собой функцию дискретной
случайной величины $G$, закон распределения которой задаётся таблицей
%.~\ref{table1}.

\begin{table}[h]
\begin{center}
%\caption{}
\label{table1}
\begin{tabular}{|c|c|c|}
\hline
$\mathbf{g}$ & 1 & 0\\
\hline
$\mathbf{p}$ & $p_\phi$ & $1-p_\phi$\\
\hline
\end{tabular}\:.\vspace*{-6mm}
\end{center}
\end{table}



{\baselineskip=0.9\baselineskip
На каждом такте работы все активные процессорные модули должны выполнять
операции чтения-записи (см. п.\,\ref{sec:osmodel}). В соответствии с этим,
активный процессорный модуль должен выбрать некоторый процесс $\phi\in\Phi$
и произвести операцию чтения с диска или записи на диск, ассоциированный с $\phi$.
Мы будем называть такой процесс \emph{активным}. Функция активности имеет
следующую семантику значений: $1$~--- процесс активен на данном такте,
$0$~--- процесс не активен.

\begin{figure}[!ht]
\begin{center}
\includegraphics{images/pchoose.eps}\vspace*{-7mm}
\begin{flushleft}
\caption{Выбор активного процесса.}
\label{fig:chprocess}
\end{flushleft}\vspace*{-12mm}
\end{center}
\end{figure}

Выбор активного процесса осуществляется следующим образом. Все процессы из
множества $\Phi$ организуются в циклический список. Вводится указатель на
текущий элемент списка (его начальная позиция может быть произвольной). При
выборе активного процесса производится циклический просмотр списка, начиная с
текущего элемента. Перебор прекращается, как только для какого-либо процесса из
списка функция активности принимает значение $1$ (см. рис.\,\ref{fig:chprocess}).

% !!! ? В следующий раз, когда будем выбирать активный, начнем со следующего
% !!! ? за выбранным?
% *** Да.
}

\section{Распределение данных и балансировка загрузки}\label{sec:strategy}

Данный раздел посвящен описанию стратегии размещения данных и алгоритма балансировки загрузки в
иерархической вычислительной системе. В разделе\,\ref{sec:symmetrical} вводится
формальное оп\-ре\-деление симметричной многопроцессорной иерархии. \linebreak Раз\-дел~\ref{sec:fragmentation}
посвящен описанию механизма фрагментации и балансировки загрузки, основанному на
введении понятия сегмента. В
разделе\,\ref{sec:Balancing} представлен алгоритм балансировки загрузки,
основанный на механизме репликации, описанном в \ref{sec:replication}.


\subsection{Симметричные иерархии}\label{sec:symmetrical}

\vspace*{0pt}

%\noindent
Архитектура многопроцессорной системы зачастую является
определяющим фактором при разработке стратегии размещения данных. В этом
разделе мы построим модель симметричной иерархической многопроцессорной системы
баз данных. В основе данной модели лежит понятие $DM$-дерева, введенное в
разделе~\ref{sec:hardwaremodel}.

Дадим определение изоморфизма двух $DM$-деревьев. Пусть $\mathfrak{E}_T$~---
множество дуг $DM$-дерева $T$; $h_M$~--- коэффициент трудоемкости узла
$M\in\mathfrak{M}_T$ в $DM$-дереве $T$. $DM$-деревья $A$ и $B$ называются
\emph{изоморфными}, если существуют взаимно однозначное отображение $f$ множества
$\mathfrak{M}_A$ на множество $\mathfrak{M}_B$ и взаимно однозначное отображение
$g$ множества $\mathfrak{E}_A$ на множество $\mathfrak{E}_B$ такие, что:

\renewcommand{\labelenumi}{(\theenumi)}\begin{enumerate}\itemузел $\nu$ является конечным узлом дуги $e$ в дереве $A$ тогда и только
тогда, когда узел $f(\nu)$ является конечным узлом дуги $g(e)$ в дереве $B$;
\itemузел $w$ является начальным узлом дуги $e$ в дереве $A$ тогда и только
тогда, когда узел $f(w)$ является начальным узлом дуги $g(e)$ в дереве $B$;\label{condition}
\item $P\in\mathfrak{P}_A\Longleftrightarrow f(P)\in\mathfrak{P}_B$;
\item $D\in\mathfrak{D}_A\Longleftrightarrow f(D)\in\mathfrak{D}_B$;
\item $N\in\mathfrak{N}_A\Longleftrightarrow f(N)\in\mathfrak{N}_B$;
\item $h_M=h_{f(M)}$.\end{enumerate}


Упорядоченную пару отображений $q=(f,g)$ будем называть \emph{изоморфизмом}
$DM$-дерева $A$ на $DM$-дерево $B$.

{
\renewcommand{\figurename}{\hfill Рис.\,}
\begin{figure}[!ht]
\begin{center}
\includegraphics{images/isoexample.eps}
\begin{flushleft}
\caption{
\mbox{Пример отображения, не являющегося изоморфизмом:\hspace*{9mm}}
\mbox{\hspace*{1.2cm}$f(n_i^A)=n_i^B$, $f(p_i^A)\,{=}\,p_i^B$, $f(d_i^A)\,{=}\,d_i^B,\:g(e_i^A)\,{=}\,e_i^B$.\,}
}
\label{fig:isoExample}
\end{flushleft}\vspace*{-7mm}
\end{center}
\end{figure}
}

Заметим, что условие~\ref{condition} из определения изоморфизма не является
избыточным. Это подтверждается примером, изображенным на рис.\,\ref{fig:isoExample}.
Действительно, используя нумерацию узлов и дуг, указанную на рис.\,\ref{fig:isoExample},
определим отображения $f$ и $g$ следующим образом (для любого $i$):
\[
f(N_i^A)=N_i^B,\quad f(P_i^A)=P_i^B, \quad f(D_i^A)=D_i^B,\quad g(e_i^A)=e_i^B.
\]
Очевидно, что отображения $f$ и $g$ удовлетворяют всем требованиям изоморфизма,
кроме условия~\ref{condition} (мы полагаем коэффициент трудоемкости для всех
узлов равным 1). Однако мы не можем признать $q=(f,g)$ изоморфизмом $DM$-дерева
$A$ на $DM$-дерево $B$, так как здесь нарушается отношение подчиненности узлов
(узел $w$ является \emph{подчиненным} по отношению к узлу $\nu$, если существует
дуга, направленная от $w$ к $\nu$). Действительно, в $DM$-дереве $A$ узел $N_2^A$
подчинен узлу $N_1^A$, а в $DM$-дереве $B$ узел $f(N_2^A)=N_2^B$ имеет в
подчинении узел $f(N_1^A)=N_1^B$.

Определим \emph{уровень узла} по отношению к дереву $T$ рекурсивно следующим
образом \cite{B_Knuth1}. Уровень корня дерева $T$ равен нулю, а уровень любого другого
узла на единицу больше, чем уровень корня минимального поддерева дерева $T$,
содержащего данный узел.

Под \emph{уровнем поддерева}\  дерева $T$ мы будем понимать уровень корня
этого поддерева в дереве $T$.

Два поддерева одного уровня называются \emph{смежными}, если
% !!!! - их корни являются братьями, т.\,е.
в дереве существует узел, являющийся общим родителем по
отношению к корневым узлам данных поддеревьев.

Определим \emph{высоту} ориентированного дерева $T$ как максимальный уровень
поддерева в этом дереве~\cite{B_Knuth3}.

Мы будем называть $DM$-дерево $T$ высоты $H$ \emph{симметричным}, если выполняются
следующие условия:

\begin{enumerate}
\itemлюбые два смежных поддерева уровня $l<H$ являются изоморфными;
\itemлюбое поддерево уровня $H-1$ содержит в точности один диск и один процессор.
\end{enumerate}

Условие~\ref{condition} в определении симметричности $DM$-дерева представляет собой
абстрактную модель SMP-системы в том смысле, что в контексте многопроцессорных
иерархий все процессоры SMP-системы могут рассматриваться как один
``мегапроцессор'', а все диски --- как один ``мегадиск''. Очевидно, что
балансировка загрузки на уровне SMP-системы должна решаться принципиально
другими методами, так как SMP-система имеет общую память и все диски в
равной мере доступны всем процессорам (см. по этому вопросу работы
\cite{B_Lu92, B_Omiecinsky91}). Определим \emph{степень узла} как
количество дуг, входящих в этот узел. В симметричном дереве все узлы одного
уровня имеют одинаковую степень, называемую \emph{степенью данного уровня}.

\subsection{Фрагментация и сегментация данных}\label{sec:fragmentation}

%\noindent
Размещение базы данных на узлах многопроцессорной иерархической системы
задается следующим образом. Каждое отношение разбивается на непересекающиеся
фрагменты, которые размещаются на различных дисковых модулях. При
этом мы используем горизонтальную фрагментацию \cite{B_Williams98} и предполагаем, что кортежи
фрагмента некоторым образом упорядочены, что
этот порядок фиксирован для каждого запроса и определяет последовательность
считывания кортежей в операции сканирования фрагмента. Мы будем называть этот
порядок \emph{естественным}. На практике естественный порядок может определяться
физическим порядком следования кортежей или индексом.

Каждый фрагмент на логическом уровне разбивается на последовательность
\emph{сегментов} фиксированной длины. Длина сегмента измеряется в кортежах и является
атрибутом фрагмента. Разбиение на сегменты выполняется в соответствии с
естественным порядком и всегда начинается с первого кортежа. В соответствии с
этим последний сегмент фрагмента может оказаться неполным.

Количество сегментов фрагмента $F$ обозначается как $S(F)$  и может быть
вычислено по формуле

\begin{equation}\label{eq:fragmentation:1}
S(F)=\left\lceil \frac{E(F)}{L(F)}\right\rceil.\end{equation}

\noindentЗдесь $E(F)$ обозначает количество кортежей во фрагменте $F$, $L(F)$~--- длину
сегмента для фрагмента $F$.

\subsection{Репликация данных}\label{sec:replication}

Раздел посвящен описанию механизма репликации данных на основе сегментов. В п.\,\ref{sec:FrmAlg} вводится понятие коэффициента репликации.
В п.\,~\ref{sec:mrmethod} описывается метод частичного зеркалирования,
использующий функцию репликации, сопоставляющую каждому уровню иерархии
определенный коэффициент репликации. Доказываются теоремы, дающие оценки для
суммарного размера реплик. П.\,\ref{sec:chfunc} посвящен проблеме выбора
функции репликации. Вводится понятие регулярной иерархии. Доказываются теоремы,
дающие оценки для трудоемкости формирования реплик при отсутствии помех.

\subsubsection{Алгоритм построения реплики}\label{sec:FrmAlg}

%\noindent
Пусть фрагмент $F_0$ размещается на дисковом модуле $D_0\in
\mathfrak{D}_T$ многопроцессорной иерархической системы $T$, и на каждом
дисковом модуле $D_i\in \mathfrak{D}_T$ $(i>0)$ располагается
\emph{частичная реплика} $F_i$, включающая в себя некоторое подмножество
(возможно пустое) кортежей фрагмента $F_0$.

Наименьшей единицей репликации данных является сегмент. Длина сегмента
реплики всегда совпадает с длиной сегмента реплицируемого фрагмента:
\[L(F_i)=L(F_0),\qquad \forall D_i\in \mathfrak{D}_T.
\]

Количество кортежей $E(F_i)$ в реплике $F_i$ задается \emph{коэффициентом репликации}
\[\mu_i\in \mathbb{R},\qquad 0\leq \mu_i\leq 1,\]
являющимся атрибутом реплики $F_i$, и вычисляется по формуле

\begin{equation}
\label{eq:FrmAlg:1}
E(F_i)=E(F_0)-\left\lceil (1-\mu_i)\cdot S(F_0)\right\rceil\cdot L(F_0).
\end{equation}

\emph{Естественный порядок кортежей реплики} $F_i$ определяется естественным порядком
кортежей фрагмента $F_0$. При этом \emph{номер $C$ первого кортежа} реплики $F_i$
вычисляется по формуле
\[
C(F_i)=E(F)-E(F_i)+1.
\]
Для пустой реплики $F_i$ будем иметь $C(F_i)=E(F_0)+1$, что соответствует
признаку ``конец файла''.

\subsubsection{Метод частичного зеркалирования}\label{sec:mrmethod}

%\noindent
Пусть заданы симметричное $DM$-дерево $T$ высоты $H>1$ и
функция репликации $r(l)$, сопоставляющая каждому уровню $l<H$
дерева $T$ коэффициент репликации $\mu=r(l)$.

Мы полагаем, что $r(H-1)=1$. Это мотивируется тем, что уровень иерархии $H-1$
включает в себя поддеревья высоты $1$, которым соответствуют SMP-системы. В
SMP-системе все диски в равной мере доступны любому процессору, поэтому нет
необходимости в физической репликации данных. На логическом уровне балансировка
загрузки осуществляется путем сегментирования исходного фрагмента, т.\,е. сам
фрагмент играет роль своей реплики.

Определим функцию репликации $r(l)$ для значений $l\leq H-2$.
\parПусть фрагмент $F_0$ располагается на диске $D_0\in \mathfrak{D}_T$.
Мы будем использовать следующий метод для построения реплики $F_i$ на диске
$D_i\in \mathfrak{D}_T$ $(i>0)$, называемый \emph{методом частичного зеркалирования}.
Построим последовательность поддеревьев дерева~$T$

\begin{equation}
\label{eq:mrmethod:1}\{ M_0, M_1,...,M_{H-2}\},
\end{equation}
обладающую следующими свойствами:

\[
\begin{cases}
l(M_j)=j, \\D_0\in \mathfrak{D}(M_j),\end{cases}
\]
\noindentдля всех $0\leq j\leq H-2$. Здесь $l(M_j)$ обозначает уровень поддерева $M_j$.
Очевидно, что для любого симметричного дерева $T$ существует только одна такая
последовательность. Найдем наибольший индекс $j\geq 1$ такой, что
\[\{ D_0, D_i\}\subset\mathfrak{D}(M_j).
\]
Мы полагаем
\begin{equation}
\label{eq:mrmethod:2}\mu_i=r(j).
\end{equation}
Для формирования реплики $F_i$ на диске $D_i$ мы используем алгоритм, описанный
в п.\,\ref{sec:FrmAlg}  с коэффициентом репликации, определяемым по формуле~(\ref{eq:mrmethod:2}).

Следующая теорема дает оценку для размера реплики.
\begin{teo}\label{teo:1}
\hspace*{-1pt}Пусть\,$T$\,---\,симметричное\,$DM$-дерево высоты\,$H\!{>}1$.
Пусть фрагмент $F_0$
располагается на диске $D_0\in \mathfrak{D}_T$. Пусть $M$---\,поддерево дерева
$T$ такое, что $0<l(M)<H$ и $D_0\in \mathfrak{D}_M$. Пусть
$M'$~--- произвольное смежное с $M$ поддерево дерева $T$. Тогда для любого
$D_i\in \mathfrak{D}_{M'}$ справедлива следующая оценка для размера реплики
$F_i$ фрагмента $F_0$, размещенной на диске $D_i${\rm:}\[E(F_i)=r(l(M)-1)\cdot
E(F_0)+O(L(F_0)),\] где $L(F_0)$~--- длина сегмента для фрагмента $F_0$.
\end{teo}
%\noindent

\proof
В соответствии с (\ref{eq:FrmAlg:1}) имеем
\[E(F_i)=E(F_0)-\left\lceil (1-\mu (F_i))\cdot S(F_0)\right\rceil\cdot
L(F_0). \]
Отсюда получаем \begin{equation}\label{eq:mrmethod:3}E(F_i)=E(F_0)-(1-\mu
(F_i))\cdot S(F_0)\cdot L(F_0)+O(L(F_0)).\end{equation}
Так как $D_0\in
\mathfrak{D}_M$, $D_i\in \mathfrak{D}_{M'}$ и поддеревья $M$ и $M'$
являются
смежными, то минимальное поддерево $\hat M$, содержащее диски $D_0$ и
$D_i$ будет иметь уровень $l(\hat M)=l(M)-1$. Тогда в соответствии
с~(\ref{eq:mrmethod:2}) получаем $\mu (F_i)=r(l(M)-1)$. Подставив это
значение в~(\ref{eq:mrmethod:3}), будем иметь
\[E(F_i)=E(F_0)-(1-r(l(M)-1))\cdot S(F_0)\cdot L(F_0)+O(L(F_0)).\]
Подставив вместо $S(F_0)$ значение из~(\ref{eq:fragmentation:1}), получим
\[
\begin{gathered}  \operatorname{E} (F_i )   =
\operatorname{E} (F_0 ) - \left( {1 - r\left( {l(M) - 1} \right)}
\right) \cdot \left\lceil {\frac{{\operatorname{E} (F_0 )}}{
{\operatorname{L} (F_0 )}}} \right\rceil  \cdot \operatorname{L} (F_0 )\  +  \\
 { } + {\rm O}\left( {\operatorname{L} (F_0 )} \right)=  \\     =
\operatorname{E} (F_0 ) - \left( {1 - r\left( {l(M) - 1} \right)} \right)
\cdot \frac{{\operatorname{E} (F_0 )}}{{\operatorname{L} (F_0 )}} \cdot
\operatorname{L} (F_0 ) + {\rm O}\left( {\operatorname{L} (F_0 )} \right)=
  \\     = \operatorname{E} (F_0 ) - \left( {1 - r\left( {l(M) - 1}
\right)} \right)\operatorname{E} (F_0 ) + {\rm O}\left(
{\operatorname{L} (F_0 )} \right)= \hfill \\     = r\left( {l(M) - 1} \right)
\operatorname{E} (F_0 ) + {\rm O}\left( {\operatorname{L} (F_0 )} \right).
\\\end{gathered}
\]
\eproof

\parЗаметим, что размер сегмента $L(F_0)$ является параметром репликации и не
связан с фрагментацией базы данных. Таким образом, мы можем считать, что $L(F_0)$
является константой, значение которой мало относительно общего размера базы
данных, и им можно пренебречь.
\parОценка суммарного размера всех реплик фрагмента может быть получена
с помощью следующей теоремы.
%\noindent
\begin{teo}\label{teo:2}
\ Пусть $T$~---\ \  симметричное\  $DM$-дерево\  высоты\
 $H\!{>}1$. Пусть фрагмент $F_0$
располагается на диске $D_0\in \mathfrak{D}_T$. Обозначим степень уровня $l$
дерева $T$ как $\delta_l$. Обозначим $R(F_0){=}$ ${=}\sum\limits_{i=1}^{\left\vert\mathfrak{D}_T\right\vert}E(F_i)$~---
суммарное количество кортежей во всех репликах фрагмента $F_0$. Тогда

\begin{equation}
\label{eq:mrmethod:4}
R(F_0)=E(F_0)\cdot \sum\limits_{j=0}^{H-2}r(j)(\delta_j-1) \prod\limits_{k=j+1}^{H-2}\delta_k+O(L(F_0)).
\end{equation}
\end{teo}

\proofДоказательство проведем индукцией по высоте $H$ дерева $T$.

Пусть $H=2$. Тогда число дисков в дереве $T$ равно $\delta_0$. В
соответствии с теоремой~\ref{teo:1} каждая реплика будет иметь размер
$T_0 (F_0)=r(0)E(F_0)+O(L(F_0))$. Следовательно, суммарное количество кортежей
во всех репликах фрагмента $F_0$ имеет следующую оценку

\begin{equation}
\label{eq:mrmethod:5}
\begin{gathered}
\operatorname{R} (F_0 )   = \left( {\operatorname{E} \left( {F_0 } \right)r\left( 0 \right) + {\rm O}\left( {\operatorname{L} (F_0 )} \right)} \right) \cdot \left( {\delta _0  - 1} \right)= \hfill \\
     = \operatorname{E} \left( {F_0 } \right)r\left( 0 \right)\left( {\delta _0  - 1} \right) + {\rm O}\left( {\operatorname{L} \left( {F_0 } \right)} \right),\end{gathered}
\end{equation}
что согласуется с (\ref{eq:mrmethod:4}) при $H=2$.
Пусть $H>2$. Тогда дерево $T$ содержит $\delta_0$ поддеревьев высоты $H-1$:
\[
M_0,M_1,...,M_{\delta_0-1}.
\]
\parОбозначим через $R_j (F_0)$ суммарное количество кортежей во всех репликах
фрагмента $F_0$, расположенных на всех дисках поддерева $M_j$. Мы имеем

\begin{equation}\label{eq:mrmethod:6}
R(F_0)=\sum\limits_{j=0}^{\delta_0-1}R_j(F_0).\end{equation}

\parБез ограничения общности можно считать, что $D_0\in \mathfrak{D}(M_0)$.
Тогда в силу симметричности дерева $T$ из~(\ref{eq:mrmethod:6}) получаем
\begin{equation}
\label{eq:mrmethod:7}R(F_0)=R_0(F_0)+(\delta_0-1)R_1(F_0).
\end{equation}
\parВ соответствии с теоремой~\ref{teo:1} любая реплика $F_i$, располагающаяся в
поддереве $M_1$, имеет следующий размер

\begin{equation}
\label{eq:mrmethod:8}E(F_i)=r(0)E(F_0)+O(L(F_0)).
\end{equation}
\parВ силу симметричности дерева $T$, суммарное количество дисков в поддереве $M_1$
равно $\prod\limits_{k=1}^{H-2}\delta_k$. Учитывая этот факт, из~(\ref{eq:mrmethod:8})
получаем

\begin{equation}
\label{eq:mrmethod:9}
\operatorname{R} _1 (F_0 ) = r\left( 0 \right)\operatorname{E} \left( {F_0 }\right)\prod\limits_{k = 1}^{H - 2} {\delta _k }  + {\rm O}\left( {\operatorname{L} (F_0 )} \right).
\end{equation}

С другой стороны, по предположению индукции имеем
\begin{equation}\label{eq:mrmethod:10}\operatorname{R} (F_0 ) =
\operatorname{E} (F_0 )\sum\limits_{j = 1}^{H - 2} {r(j)(\delta _j  -
1)\prod\limits_{k = j + 1}^{H - 2}{\delta _k } }  + {\rm O}\left(
{\operatorname{L} (F_0 )} \right).\end{equation}
Подставляя в~(\ref{eq:mrmethod:7}) значения правых частей
из~(\ref{eq:mrmethod:9}) и~(\ref{eq:mrmethod:10}), имеем
\[
\begin{gathered}
\operatorname{R} (F_0 )   = \operatorname{E} (F_0 )\sum\limits_{j = 1}^{H - 2}
{r(j)\prod\limits_{k = j + 1}^{H - 2} {\delta _k } } \  + \hfill \\
{ } + (\delta _0  - 1)r
\left( 0 \right)\operatorname{E} \left( {F_0 } \right)\prod\limits_{k = 1}^{H - 2}
{\delta _k }  + {\rm O}\left( {\operatorname{L} (F_0 )} \right)= \hfill \\
= \operatorname{E} (F_0 )\sum\limits_{j = 0}^{H - 2} {r(j)(\delta _j  - 1)
\prod\limits_{k = j + 1}^{H - 2} {\delta _k } }  + {\rm O}\left(
{\operatorname{L} (F_0 )} \right). \hfill \\\end{gathered}
\]
\eproof
\subsubsection{Выбор функции репликации}\label{sec:chfunc}

%\par\noindent
При выборе функции репликации $r(l)$ целесообразно учитывать
коэффициенты трудоемкости узлов $DM$-дерева. Очевидно, что в симметричном
$DM$-дереве все вершины уровня $l$ имеют одинаковую трудоемкость $h(l)$,
которую мы будем называть \emph{трудоемкостью уровня} $l$.

Назовем симметричное $DM$-дерево $T$ \emph{регулярным}, если для любых двух
уровней $l$ и $l'$ дерева $T$ справедливо

\begin{equation}\label{eq:chfunc:1}l < l'\qquad   \Rightarrow\qquad   h (l) \geqslant h(l')\:,\end{equation}

\noindentт.\,е. чем выше уровень в иерархии, тем больше его трудоемкость.

Следующая теорема позволяет получить оценку трудоемкости покортежного
формирования реплики в регулярном $DM$-дереве.
%\noindent
\begin{teo}\label{teo:3}
Пусть $T$~--- регулярное\  $DM$-дерево\  высоты $H{>}1$. Пусть фрагмент $F_0$
располагается на диске $D_0\in \mathfrak{D}_T$. Пусть $M$~--- поддерево дерева
$T$, такое, что  $0{<}\,l(M){<}\,H\!{-}1$ и $D_0{\in}\,\mathfrak{D}_M$. Пусть $M'$~---
произвольное смежное с $M$ поддерево дерева $T$; $F_i$~--- реплика фрагмента $F_0$,
размещенная на диске $D_i\in\mathfrak{D}_{M'}$. Обозначим $\tau(F_i)$~---
трудоемкость покортежного формирования реплики $F_i$ при отсутствии помех. Тогда
\[\tau (F_i ) = h \left( {l(M) - 1} \right) \cdot r\left( {l(M) - 1}\right)\operatorname{E} \left( {F_0 } \right) + {\rm O}\left( {h_0 }\right),
\]
где $h_0=h(0)$~--- коэффициент трудоемкости корня дерева $T$.
\end{teo}

\proof
\  Организуем\  конвейерную\  передачу кортежей с диска $D_0\in\mathfrak{D}(M')$
в соответствии с моделью операционной среды, описанной в разделе~\ref{sec:osmodel}.
Скорость работы конвейера определяется самым медленным узлом. Так как $M$ и  $M'$
являются смежными поддеревьями, их корневые узлы имеют общего родителя уровня $l(M-1)$,
который в соответствии с~(\ref{eq:chfunc:1}) и будет самым медленным звеном
конвейера. Следовательно, трудоемкость передачи одного кортежа при полностью
запущенном конвейере равна $h(l(M)-1)$. Отсюда

\begin{equation}\label{eq:chfunc:2}
\tau (F_i ) = h \left( {l(M) - 1} \right)\operatorname{E} (F_i ) + {\rm O}\left( {h \left( {l(M) - 1} \right)} \right).\end{equation}
Здесь $O(h(l(M)-1))$ обозначает верхнюю границу для времени, необходимого
для полного ``разгона''  конвейера в предположении, что высота дерева $T$ является
константой.

Так как $T$ регулярно, то $h(l(M)-1)\leq h_0$. На основании этого из~(\ref{eq:chfunc:2})
получаем

\begin{equation}\label{eq:chfunc:3}
\tau (F_i ) = h \left( {l(M) - 1} \right)\operatorname{E} (F_i ) +{\rm O}\left( {h_0 } \right).
\end{equation}
По теореме~\ref{teo:1} из (\ref{eq:chfunc:3}) получаем

\begin{equation}
\label{eq:chfunc:4}
\begin{gathered}
\tau (F_i )   = h \left( {l(M) {-} 1} \right) \cdot r\left( {l(M){-}1}\right)\operatorname{E} \left( {F_0 } \right)\
+\hfill \\
{ }  +{\rm O}\left( {h_0 }\right){\rm O}\left( {\operatorname{L} (F_0 )} \right)
 + {\rm O}\left( {h_0 } \right).
\end{gathered}
\end{equation}
\parМы вправе считать, что длина сегмента не меняется в процессе формирования
реплики, т.\,е. $L(F_0)$   является константой. Тогда из~(\ref{eq:chfunc:4})
получаем
\[
\begin{gathered}
  \tau (F_i )   = h \left( {l(M) - 1} \right) \cdot r\left( {l(M) - 1} \right)
\operatorname{E} \left( {F_0 } \right) + {\rm O}\left( {h_0 } \right) + {\rm O}
\left( {h_0 } \right)= \hfill \\
     = h \left( {l(M) - 1} \right) \cdot r\left( {l(M) - 1} \right)\operatorname{E} \left( {F_0 } \right) + {\rm O}\left( {h_0 } \right).\end{gathered}
\]
\eproof

Оценка трудоемкости покортежного формирования всех реплик фрагмента без учета
помех может быть получена с помощью следующей теоремы.
%\noindent
\begin{teo}\label{teo:4}
Пусть $T$~--- регулярное $DM$-дерево высоты $H>1$. Пусть фрагмент $F_0$
располагается на диске $D_0\in\mathfrak{D}_T$. Обозначим степень уровня $l$
дерева $T$ как $\delta_l$. Обозначим $\tau(F_0)={=}\sum\limits_{i=1}^{\left\vert\mathfrak{D}_T\right\vert}t(F_i)$~--- суммарная трудоемкость покортежного формирования всех реплик фрагмента $F_0$
без учета помех. Тогда
\begin{equation}\label{eq:chfunc:5}
\tau (F_0 ) = \operatorname{E} \left( {F_0 } \right)\sum\limits_{j = 0}^{H - 2} {h \left( j \right)r\left( j \right)\left( {\delta _j  - 1} \right)\prod\limits_{k = j + 1}^{H - 2} {\delta _k } }  + {\rm O}\left( {h_0 } \right).\end{equation}\end{teo}

\proofДоказательство проведем индукцией по высоте $H$ дерева $T$.

Пусть $H=2$. Тогда число дисков в дереве $T$ равно $\delta_0$.
В соответствии с теоремой~\ref{teo:3} трудоемкость покортежного формирования
любой реплики фрагмента $F_0$ в этом случае имеет следующую оценку:
\[\tau (F_i ) = h \left( 0 \right) \cdot r\left( 0 \right)\operatorname{E}\left( {F_0 } \right) + {\rm O}\left( {h_0 } \right).\]
Следовательно, суммарная трудоемкость покортежного формирования всех реплик
фрагмента $F_0$ без учета помех может быть оценена следующим образом:
\[\tau (F_i ) = h \left( 0 \right)r\left( 0 \right)\operatorname{E}\left( {F_0 } \right)\left( {\delta _0  - 1} \right) + {\rm O}\left( {h_0 } \right),
\]
что согласуется с (\ref{eq:chfunc:5}) при $H=2$.

Пусть $H>2$. Тогда дерево $T$ содержит $\delta_0$ поддеревьев высоты $H-1$:
\[
M_0,M_1,...,M_{\delta_0-1}.
\]
Обозначим через $\tau_j(F_0)$ суммарную трудоемкость формирования без учета
помех всех реплик фрагмента $F_0$, расположенных на всех дисках поддерева $M_j$.
Мы имеем

\begin{equation}\label{eq:chfunc:6}
\tau(F_0)=\sum\limits_{j=0}^{\delta_0-1}\tau_j(F_0).\end{equation}

Без ограничения общности можно считать, что $D_0\in\mathfrak{D}(M_0)$.
Тогда в силу симметричности дерева $T$ из~(\ref{eq:chfunc:6}) получаем

\begin{equation}\label{eq:chfunc:7}\tau (F_0 ) = \tau _0 (F_0 ) + (\delta _0  - 1)\tau _1 (F_0 ).\end{equation}

В соответствии с теоремой~\ref{teo:3} для любой реплики $F_i$, располагающейся
в поддереве $M_1$, имеем

\begin{equation}\label{eq:chfunc:8}
\tau (F_i ) = h (0)r\left( 0 \right)\operatorname{E} \left( {F_0 }\right) + {\rm O}\left( {h_0 } \right).\end{equation}

В силу симметричности дерева $T$ суммарное количество дисков в поддереве $M_1$
равно $\sum\limits_{k=1}^{H-2}\delta_k$. Учитывая этот факт, из~(\ref{eq:chfunc:8})
получаем

\begin{equation}\label{eq:chfunc:9}
\tau _1 (F_0 ) = h (0)r\left( 0 \right)\operatorname{E} \left( {F_0 } \right)\prod\limits_{k = 1}^{H - 2} {\delta _k }  + {\rm O}\left( {h_0 } \right).
\end{equation}

С другой стороны, по предположению индукции имеем

\begin{equation}\label{eq:chfunc:10}
\tau _0 (F_0 ) = \operatorname{E} \left( {F_0 } \right)\sum\limits_{j = 1}^{H - 2} {h \left( j \right)r\left( j \right)\left( {\delta _j  - 1} \right)\prod\limits_{k = j + 1}^{H - 2} {\delta _k } }  + {\rm O}\left( {h_0 } \right).\end{equation}
Подставляя в~(\ref{eq:chfunc:7}) значения правых частей из~(\ref{eq:chfunc:9}) и(~\ref{eq:chfunc:10}), имеем
\[
\begin{gathered}
\tau (F_0 )   = \operatorname{E} \left( {F_0 } \right)\sum\limits_{j = 1}^{H - 2}
{h \left( j \right)r\left( j \right)\left( {\delta _j  - 1} \right)\prod
\limits_{k = j + 1}^{H - 2} {\delta _k } }\   +\hfill \\ \hfill{ } + (\delta _0  - 1)h (0)r\left( 0
\right)\operatorname{E} \left( {F_0 } \right)\prod\limits_{k = 1}^{H - 2}
{\delta _k }  + {\rm O}\left( {h_0 } \right)= \hfill \\     = \operatorname{E} \left( {F_0 } \right)\sum\limits_{j = 0}^{H - 2} {h \left( j \right)r\left( j \right)\left( {\delta _j  - 1} \right)\prod\limits_{k = j + 1}^{H - 2} {\delta _k } }  + {\rm O}\left( {h_0 } \right). \hfill \\\end{gathered}
\]
\eproof

Определим рекурсивно \emph{нормальную} функцию репликации $r(l)$
следующим образом:

\renewcommand{\labelenumi}{\theenumi)}
\begin{enumerate}
\itemдля $l=H-2:\qquad r(H-2)=\frac{\displaystyle 1}{\displaystyle h(H-2)(\delta_{H-2}-1)}$;
\itemдля $0\leq l\leq H-2:\qquad
r(l)=\frac{\displaystyle r(l+1)h(l+1)(\delta_{l+1}-1)}{\displaystyle h(l)(\delta_l-1)\delta_{l+1}}$.
\end{enumerate}

Справедлива следующая теорема,
доказываемая непосредственно из теоремы~\ref{teo:4} и
определения нормальной функции репликации.
%\noindent
\begin{teo}\label{teo:5}
Пусть\,\,$T$~--- регулярное $DM$-дерево высоты $H\!{>}1$. Пусть $\mathbb{F}$~---
множество фрагментов, составляющих базу данных. Пусть $\mathbb{R}$~---
множество всех реплик всех фрагментов из
множества\ \  $\mathbb{F}$,\ \  построенных\  с\  использованием\  нормальной
функции репликации. Пусть $E(\mathbb{F})$~--- размер
базы данных в кортежах \rm{(}здесь мы предполагаем, что все кортежи имеют одинаковую
длину в байтах \rm{)}. $\tau(\mathbb{R})$~--- суммарная трудоемкость покортежного
формирования всех реплик без учета помех. Тогда
\[\tau(\mathbb{R})\approx kE(\mathbb{F}),\]
где $k$~--- некоторая константа, не зависящая от $\mathbb{F}$.
\end{teo}
%\proof Доказательство непосредственно следует из теоремы~\ref{teo:4} и
%определения нормальной функции репликации.

\hspace*{-2pt}Данная теорема показывает, что при использовании нормальной функции
репликации трудоемкость обновления реплик в регулярной многопроцессорной
иерархической системе пропорциональна размеру обновляемой части базы данных
при условии, что соединительная сеть обладает достаточной пропускной способностью.


\subsection{Алгоритм балансировки загрузки}\label{sec:Balancing}

При обработке запроса часто возникают ситуации, когда наибольшая
доля работы выпадает на один процессорный модуль или целый сегмент
вычислительной системы. В таких случаях после высвобождения
менее загруженные процессоры берут на себя часть работы.
В основе предлагаемого
в данной статье алгоритма балансировки загрузки лежит метод зеркалирования~\cite{B_Sok01}.
Использование зеркалирования позволяет избежать пересылок дисковых данных по
сети. Для обработки удаленный процессор использует реплику ближайшего к
загруженному процессору диска. Процессорному модулю, участвующему в балансировке,
выделяется набор сегментов реплики, а не реплика целиком, что позволяет
участвовать в балансировке сразу нескольким процессорным модулям.

Пусть $T$~--- симметричное $DM$-дерево высоты $H$, $P_1,...,P_m$~---
процессорные модули $T$, $Q_1(F_1,...,F_l),...,Q_m(F_1,...,F_l)$~--- параллельные
агенты физического плана запроса. Каждый из входных блоков данных агента
характеризуется четверкой параметров:
\renewcommand{\labelenumi}{(\theenumi)}
\begin{enumerate}
\item$p$~--- указатель на фрагмент;
\item$f$~--- номер начального сегмента;
\item$q$~--- количество обрабатываемых сегментов;
\item$c$~--- текущий обрабатываемый сегмент.
\end{enumerate}

Параллельный агент   может находиться в одном из двух состояний: выполнение
и ожидание. В состоянии ожидания происходит инициализация параметров агента. В
состоянии выполнения агент занимается обработкой входных данных. Данные
выделяются агенту сегментами, в соответствии с естественным порядком следования
кортежей. Перед началом обработки каждого сегмента агент $Q_i$ устанавливает
параметр $c$ равным порядковому номеру текущего обрабатываемого сегмента.
Выражение $c=f+q$, является условием перехода агента $Q_i$ в состояние ожидания.

Перед началом обработки запроса каждый из входных блоков данных
параллельного агента $Q_i$ инициализируется следующими значениями:
\renewcommand{\labelenumi}{(\theenumi)}
\begin{enumerate}
\item $p$~--- указатель на фрагмент $F_i$, расположенный на диске $D_i$
процессорного модуля $P_i$, содержащего параллельный агент $Q_i$;
\item $f$~--- первый сегмент фрагмента $F_i$;
\item $q$~--- количество сегментов фрагмента $F_i$, не зеркалированных ни на одном
из остальных дисковых модулей, т.\,е. $q=\left\lceil S(F_i)\cdot(1-\max_{1\leq l\leq H}{r(l)})\right\rceil$,
где $r(l)$~--- функция репликации в $DM$-дереве $Т$.
\end{enumerate}

Балансировка загрузки в процессе обработки запроса происходит следующим
образом. Пусть агент $Q_i$ завершил обработку выделенных ему данных и перешел в
состояние ожидания. После этого вычисляется наиболее загруженный процессорный
модуль, и агенту $Q_i$ выделяется часть его работы. Наиболее загруженный
процессорный модуль выбирается из тех процессорных модулей, расстояние до
которых не превышает $j$. Критерием загруженности процессорного модуля является
количество обработанных кортежей фрагмента на смежном с процессорным модулем
диске. Чем меньше количество обработанных кортежей на смежном процессору диске,
тем более загруженным считается процессорный модуль. Формально, задача выбора
загруженного процессорного модуля сводится к поиску максимума функции:
$m(k)=\lambda_j(P_k,P_i)\cdot\bar{S}(F_k)$, по всем $k:$ $1\leq k\leq n$, где $\bar{S}(F_k)$~---
 количество необработанных сегментов фрагмента $F_k$. Функция~$\lambda_j$ принимает
значение, равное единице, если расстояние от $P_i$ до $P_k$ не превосходит $j$.
В противном случае, $\lambda_j=0$.
Количество выделяемых сегментов определяется по формуле
\[
\left\lceil {\frac{{\min (\bar S(F_k^i ) \cdot \operatorname{L} (F_k ),\;
E(F_k^i ))}}{{\delta _j }}} \right\rceil,
\]
где $\delta_j$~--- степень уровня j дерева Т.
Номер первого кортежа
\[
C(F_k ) = E(F_k ) - \min (\bar S(F_k ) \cdot \operatorname{L} (F_k ),\;E(F_k^i )) + 1.
\]
В процессе обработки запроса может возникнуть ситуация, когда узел, содержащий
агент $Q_i$, не сможет помочь ни одному из смежных с ним на уровне $j$ узлов.
Это происходит в том случае, когда фрагменты первичных дисков всех смежных узлов
целиком обработаны. Данная ситуация задается условием

\begin{equation}\label{eq:balancing:1}
\sum\limits_{k = 1}^n {\lambda _j (D_k ,D_i ) \cdot \bar S(F_k )}  = 0.
\end{equation}
Если (\ref{eq:balancing:1}) выполняется, то наиболее загруженный
процессорный модуль выбирается из процессорных модулей, находящихся на
расстоянии $j+1$ от $P_i$. Агент $Q_i$ завершает свою работу, если~(\ref{eq:balancing:1})
истинно при $j=H-1$.
%   \input{balancing.tex}

\section{Организация параллельной обработки запросов}\label{sec:QueryPr}

Общая схема обработки запроса в иерархической параллельной системе баз данных
представлена на рис.\,\ref{fig:QueryPr}
(в данном случае мы считаем, что вычислительная система имеет двухуровневую
иерархическую архитектуру и состоит из двух вычислительных узлов,
каждый из которых содержит четыре процессорных модуля).

\begin{figure}[!ht]
\begin{center}
\includegraphics{images/qprocessing.eps}
\begin{flushleft}
\caption{
Схема обработки запроса в иерархической параллельной системе баз данных.\
$Q$~--- последовательный физический план,\
$A_{i}$~--- агент 1-го уровня,\ $a_{ij}$~--- агент 2-го уровня,\ $PM_{ij}$~---
процессорный модуль,\ $\Omega_{i}$~--- вычислительный узел.
}\label{fig:QueryPr}
\end{flushleft}
\end{center}
\end{figure}

В соответствие с этой схемой запрос на языке SQL передается пользователем на
host-машину. Там он транслируется в некоторый \emph{последовательный физический план}
\cite{B_Graefe93}. Данный последовательный физический план преобразуется в \emph{параллельный план
1-го уровня}, представляющий собой совокупность \emph{агентов 1-го уровня}.
Каждый агент 1-го уровня, кроме реляционных операций, может содержать
специальные \emph{параллельные} операции \texttt{psplit} \emph{(расщепление)} и \texttt{pmerge} \emph{(слияние)},
семантика которых описывается в~\cite{B_Sok01}. Параллельный план 1-го уровня
задает распараллеливание запроса с точностью до вычислительного узла.

На следующем этапе параллельный план 1-го уровня преобразуется в \emph{параллельный
план 2-го уровня}. При этом каждый агент 1-го уровня отображается в \emph{n} агентов
2-го уровня. Здесь \emph{n} обозначает количество процессорных модулей в
вычислительной системе (на рис.\,\ref{fig:QueryPr} $n=4$). Это достигается путем вставки оператора
обмена \texttt{exchange}~\cite{B_Sok01} в соответствующие места дерева запроса.
Параллельный план 2-го уровня задает распараллеливание запроса с точностью
до процессорного модуля.

На завершающем этапе агенты 2-го уровня пересылаются с host-машины на
соответствующие процессорные модули, где \emph{интерпретируются} исполнителем
запросов. Результаты выполнения агентов в пределах одного вычислительного узла
объединяются корневым оператором \texttt{exchange} на нулевом процессорном модуле.
Если запрос выполнялся на нескольких вычислительных узлах, то суммарный результат
получается путем выполнения операции \texttt{pmerge} на нулевом узле одного из
вычислительных узлов, откуда передается на host-машину.

Рассылка параллельных агентов и передача данных в иерархической системе осуществляется
на основе системы передачи сообщений, состоящей из двух подсистем: кондуктора и
маршрутизатора. Кондуктор обеспечивает передачу сообщений между процессорными
модулями одного вычислительного узла. Маршрутизатор обеспечивает передачу
сообщений между разными вычислительными узлами.

Поясним цикл обработки запроса в параллельной системе баз данных на следующем \emph{\bfпримере}. Пусть
необходимо вычислить $\mathbf{Q=R\ \bowtie\ S}$ -- соединение двух
отношений $\mathbf{R}$ и $\mathbf{S}$ по некоторому общему атрибуту $Y$. Пусть $\mathbf{R}$
фрагментировано по атрибуту соединения на двух вычислительных узлах $\mathbf{\Omega_{0}}$ и
$\mathbf{\Omega_{1}}$ в виде двух фрагментов $R_{0}$ и $R_{1}$, т.\,е.
\[\mathbf{R}=R_{0}\cup R_{1},\qquad R_{0}\cap R_{1}=\emptyset,\qquad\pi_{Y}(R_{0})\cap\pi_{Y}(R_{1})=\emptyset,\]
где $\pi$~--- операция проекции \cite{B_GarMol00}. Пусть $\mathbf{S}$
фрагментировано по атрибуту соединения на тех же двух вычислительных узлах
$\mathbf{\Omega_{0}}$ и $\mathbf{\Omega_{1}}$ в виде двух фрагментов $S_{0}$ и $S_{1}$,
т.\,е.
\[\mathbf{S}=S_{0}\cup S_{1},\qquad S_{0}\cap S_{1}=\emptyset,\qquad\pi_{Y}(S_{0})\cap\pi_{Y}(S_{1})=\emptyset.\]
Тогда последовательный физический план запроса $\mathbf{Q}$ и соответствующий ему
параллельный план 1-го уровня будут иметь вид, изображенный на рис.\,\ref{fig:ExecPlans}.
Параллельный план 1-го уровня в данном случае включает в себя двух агентов $A_{0}$
и $A_{1}$, которые будут выполняться на вычислительных узлах $\mathbf{\Omega_{0}}$ и $\mathbf{\Omega_{1}}$,
соответственно. Агент $A_{0}$ в отличие от агента $A_{1}$ имеет дополнительную
операцию \texttt{pmerge} в качестве корневого узла. В качестве входных потоков
операции \texttt{pmerge} фигурируют склад, ассоциированный с операцией \texttt{join},
и канал маршрутизатора, ассоциированный с агентом $A_{1}$.

\begin{figure}[!ht]
\begin{center}
\includegraphics[scale=0.9]{images/execplans.eps}
\begin{flushleft}
\caption{ Последовательный физический план и параллельный план 1-го
уровня для запроса $\mathbf{Q=R\ \bowtie\ S}$.}
\label{fig:ExecPlans}
\end{flushleft}
\end{center}
\end{figure}

В качестве выходного потока операции \texttt{pmerge} указывается стандартный
поток вывода на терминал host-машины. В качестве корневого узла агента $A_{1}$
фигурирует операция \texttt{join}, выходным потоком которой является канал
маршрутизатора, ассоциированный с агентом $A_{0}$.

Рассмотрим теперь на примере агента $A_{1}$ преобразование параллельного плана
1-го уровня в параллельный план 2-го уровня. Для простоты мы будем далее
предполагать, что в качестве алгоритма операции соединения используется
алгоритм вложенных циклов \cite{B_GarMol00}, причем во внутреннем цикле
всегда сканируются кортежи из $\mathbf{S}$. Сначала рассмотрим ситуацию, когда
$R_{1}$ и $S_{1}$ фрагментированы внутри вычислительного узла по атрибуту соединения
$Y$ с использованием одной и той же функции фрагментации:
\[R_1  = \bigcup\limits_{j = 0}^3 {R_{1j} }
{\rm{ }}{\rm{,\qquad  }}\bigcap\limits_{j = 0}^3 {R_{1j} }  = \emptyset {\rm{ }}
{\rm{,\qquad }}\forall _{i \ne j}  \pi _Y (R_{1i} )\bigcap {\pi _Y (R_{1j} )}  = \emptyset\:,\]
\[
S_1  = \bigcup\limits_{j = 0}^3 {S_{1j} } {\rm{ }}{\rm{,\qquad  }}
\bigcap\limits_{j = 0}^3 {S_{1j} }  = \emptyset {\rm{ }}{\rm{,\qquad }}
\forall _{i \ne j}  \pi _Y (S_{1i} )\bigcap {\pi _Y (S_{1j} )}  = \emptyset\:,
\]
\[
\forall _{i \ne j}  \pi _Y (R_{1i} )\bigcap {\pi _Y (S_{1j} )}  = \emptyset\:.
\]
В этом случае агент 1-го уровня  $A_{1}$ преобразуется в четырех агентов 2-го
уровня $A_{10}$, $A_{11}$, $A_{12}$, $A_{13}$ (по числу процессорных модулей
в вычислительном узле), как это показано на рис.~10.
%\ref{fig:ConvAgent1}.
%\begin{figure}[!ht]

Отметим, что все четыре агента 2-го уровня абсолютно идентичны, за исключением
индексов исходных фрагментов отношений. Они получаются из агента $A_{1}$
путем вставки в корень дерева оператора обмена $\mathtt{exchange_{e_{1}}}$
(мы будем проставлять индекс у каждого оператора \texttt{exchange}, чтобы
различать различные операторы в пределах одного дерева). В нашей конфигурации
любой оператор \texttt{exchange} создает три канала для связи со
всеми процессорными модулями вычислительного узла, кроме собственного (мы
предположили, что количество процессорных модулей вычислительного узла равно четырем).
Канал кондуктора однозначно идентифицируется парой $(C, P)$, где $C$~--- логический
номер процессорного модуля в вычислительном узле, $P$~--- номер порта. В простейшем
случае в качестве номера порта можно взять порядковый номер оператора \texttt{exchange}
в дереве агента. Для каждого оператора \texttt{exchange} должна быть указана функция
распределения, определяющая, на каком процессорном модуле вычислительного узла должен
быть обработан тот или иной кортеж, помещенный во входной поток оператора
\texttt{exchange}. В данном случае оператор $\mathtt{exchange_{e_{1}}}$ имеет функцию
распределения, задаваемую формулой \[f(x)=0.\]
\newpage
\begin{center}
\includegraphics[scale=0.9]{images/ConvAgent1.eps}
\end{center}
%\begin{flushleft}
{Рис.~10.~Преобразование агента 1-го уровня в
совокупность агентов 2-го уровня для случая, когда $R_{1}$ и $S_{1}$
одинаково фрагментированы по атрибуту соединения. $C_{A_{ij}}$~---
номер процессорного модуля в вычислительном узле, на котором будет
выполняться агент $A_{ij}$,\ $P_{e_{l}}$~--- номер порта обмена,
ассоциированного с оператором \texttt{exchange} с номером $e_{l}$,\
$\approx$~--- балансировка загрузки.} %\label{fig:ConvAgent1}
%\end{flushleft}
%\end{center}
%\end{figure}
\thispagestyle{empty}
\newpage



Это означает, что все кортежи, полученные в результате выполнения операции
\texttt{join}, должны быть отправлены на нулевой процессорный модуль кластера
$\mathbf{\Omega_{1}}$ (т.\,е. для агентов $A_{11}$, $A_{12}$, $A_{13}$ выходной
поток оператора $\mathtt{exchange_{e_{1}}}$ будет всегда пуст). Из нулевого
процессорного модуля кластера $\mathbf{\Omega_{1}}$ кортежи результирующего
отношения будут переданы на нулевой процессорный модуль кластера $\mathbf{\Omega_{0}}$
в качестве входного потока операции \texttt{pmerge}.

Символы $\approx$ отмечают фрагменты отношений, к которым может быть применен
алгоритм балансировки загрузки, описываемый в разделе~\ref{sec:Balancing}. В данном
случае балансировка может осуществляться только \emph{синхронно} между обоими входными
отношениями за счет динамического изменения общей функции фрагментации. В
противном случае результат операции соединения может получиться неверным.

Предположим теперь, что $R_{1}$ фрагментирован внутри вычислительного узла
произвольным образом, а $S_{1}$~--- по-прежнему по атрибуту соединения $Y$.
В этом случае агент 1-го уровня $A_{1}$ преобразуется в четырех агентов 2-го
уровня так, как это показано на рис.~11.
%\ref{fig:ConvAgent2}.
Все агенты 2-го
уровня идентичны, за исключением индексов исходных фрагментов отношений.
Оператор $\mathtt{exchange_{e_{1}}}$ не может динамически меняться, поскольку в
момент ее изменения в выходном складе оператора могут находиться необработанные
кортежи, что может привести в итоге к неверному результату операции соединения.
Тем не менее, отсутствие динамической балансировки применительно к фрагментам
$S_{10},...,S_{13}$ не приведет к ощутимому дисбалансу в загрузке процессорных
модулей вычислительного узла, так как мы сохраняем возможность использования алгоритма
балансировки применительно к фрагментам $R_{10},...,R_{13}$, сканируемым во
внешнем цикле операции соединения.



В заключение рассмотрим случай, когда оба отношения $R_{1}$ и $S_{1}$
фрагментированы внутри Омега-кластера произвольным образом. В этом случае агент
1-го уровня $A_{1}$ преобразуется в четырех агентов 2-го уровня так, как это
показано на рис.~12.
%\ref{fig:ConvAgent3}.

%\addtocounter{page}{1}

Все агенты 2-го уровня по-прежнему идентичны, за исключением индексов исходных
фрагментов отношений. Оператор $\mathtt{exchange_{e_{1}}}$ имеет функцию
распределения $f(r)=0$, как это было в предыдущих случаях. В качестве
функции распределения для операторов $\mathtt{exchange_{e_{2}}}$ и $\mathtt{exchange_{e_{3}}}$
можно использовать произвольную, но одну и ту же функцию фрагментации по
атрибуту $Y$. При этом мы можем применять алгоритм балансировки загрузки ко
всем входным фрагментам независимо друг от друга.\\[-6ex]
%   \input{QueryPr.tex}

%\newpage
%\addtocounter{page}{2}
\section{Заключение}\label{sec:conclusion}
В данной работе были рассмотрены проблемы эффективной организации
систем баз данных на мультипроцессорных вычислительных системах с иерархической
архитектурой.

Предложена модель машины баз данных, позволяющая моделировать различные
конфигурации иерархических вычислительных систем. На основе предложенной модели
нами был спроектирован и реализован программный комплекс, получивший название
ЭВМБД (Эмулятор Виртуальных Мультипроцессоров Баз Данных). Данный программный
комплекс может быть использован для моделирования и сравнительного анализа
различных иерархических многопроцессорных архитектур в контексте задач класса
OLTP. Был проведен эксперимент по моделированию архитектуры
высокопроизводительного вычислительного кластера Южно-Уральского
государственного университета~\cite{B_Cluster}. Полученные на
эмуляторе результаты достаточно хорошо согласуются с реальными результатами,
полученными при использовании прототипа параллельной СУБД Омега.

Введена модель симметричной многопроцессорной иерархической системы.
%Эта модель
Модель описывает достаточно широкий класс реальных систем и является
математическим фундаментом для определения стратегии распределения данных в
многопроцессорных иерархиях. Для симметричной иерархии предложен алгоритм
формирования реплик, базирующийся на логическом разбиении фрагмента отношения
на сегменты равной длины. На основе этого алгоритма разработан метод частичного
зеркалирования, предполагающий задание функции репликации. Функция репликации
отображает уровень иерархии в коэффициент репликации, который определяет размер
реплики по отношению к реплицируемому фрагменту. Доказаны теоремы, позволяющие
получить оценки для размеров реплик и трудоемкости их формирования без учета
помех. Предложен вариант функции репликации, при котором трудоемкость обновления
реплик в многопроцессорной иерархической системе пропорциональна размеру
обновляемой части базы данных при условии, что соединительная сеть обладает
достаточной пропускной способностью. Описан алгоритм балансировки загрузки,
основанный на методе частичного зеркалирования.


Предложена новая модель распараллеливания запросов, ориентированная на иерархические многопроцессорные архитектуры. Данная модель позволяет выполнять на мультипроцессорной системе много различных запросов одновременно. Каждый из этих запросов может быть автоматически распараллелен на любом уровне многопроцессорной иерархии.

В качестве основных направлений дальнейших исследований можно выделить следующие.
Во-первых, это~--- аналитическое получение оценок трудоемкости обновления реплик с
учетом помех. Во-вторых, мы планируем на базе DMM модели разработать программу,
моделирующую работу иерархической многопроцессорной системы баз данных, и
провести с ее помощью эксперименты по исследованию механизмов распределения данных
и балансировки загрузки. В-третьих, мы предполагаем реализовать описанные методы
и алгоритмы в прототипе параллельной СУБД Омега~\cite{B_Proto} для кластеров и Grid систем.
\addtocounter{page}{2}

\newpage

%\begin{figure}[!ht]
\newpage
\thispagestyle{empty}
\begin{center}
\includegraphics[scale=0.85]{images/ConvAgent2.eps}\label{fig:ConvAgent2}
\end{center}
%\begin{flushleft}
{Рис.~11.\ \  Преобразование агента 1-го уровня в совокупность агентов
2-го уровня для случая, когда $R_{1}$ фрагментировано произвольным образом, а
$S_{1}$~--- по атрибуту соединения. $C_{A_{ij}}$~--- номер процессорного модуля в
вычислительном узле, на котором будет выполняться агент $A_{ij}$,\ $P_{e_{l}}$~---
номер порта обмена, ассоциированного с оператором \texttt{exchange} с номером $e_{l}$,\
$f$~--- функция распределения для оператора \texttt{exchange},\
$\approx$~--- балансировка загрузки.}
%\label{fig:ConvAgent2}
%\end{flushleft}
%\end{center}
%\end{figure}

%\begin{figure}[!ht]
\newpage
\thispagestyle{empty}
\begin{center}
\includegraphics[scale=0.9]{images/ConvAgent3.eps}\label{fig:ConvAgent3}
\end{center}
%\begin{flushleft}
{Рис.~12. Преобразование агента 1-го уровня в совокупность агентов
2-го уровня для случая, когда оба отношения $R_{1}$ и $S_{1}$ фрагментированы
произвольным образом. $C_{A_{ij}}$~--- номер процессорного модуля на
вычислительном узле, на котором будет выполняться агент $A_{ij}$,\ $P_{e_{l}}$~---
номер порта обмена, ассоциированного с оператором \texttt{exchange} с номером $e_{l}$,\
$f$~--- функция распределения для оператора \texttt{exchange},\
$\approx$~--- балансировка загрузки.}
%\label{fig:ConvAgent3}
%\end{flushleft}
%\end{center}
%\end{figure}


\newpage
\renewcommand{\labelenumi}{\theenumi.}
\setcounter{page}{81}
\begin{ltrtr}

\bibitem{B_Bhide88a}
{\it Bhide A., Stonebraker M.}
A Performance Comparison of Two Architectures for Fast Transaction
Processing // Proceedings of the Fourth International Conference on Data Engineering,
February 1-5, 1988, Los Angeles, California, USA. IEEE Com\-pu\-ter Society, 1988. P. 536--545.

\bibitem{B_Bhide88b}
{\it Bhide A.}
An Analysis of Three Transaction Processing Ar\-chi\-tec\-tu\-res // Fourteenth International
Conference on Very Large Data Bases (VLDB'88), August 29 --- September 1, 1988,
Los Angeles, California, USA, Proceedings. Morgan Kauf\-mann, 1988. P.\,339--350.

\bibitem{B_Bitton88}
{\it Bitton D., Gray J.}
Disk Shadowing // Fourteenth In\-ter\-na\-tio\-nal Conference on Very Large Data Bases,
August 29 --- September 1, 1988, Los Angeles, California, USA, Proceedings.
Morgan Kaufmann. 1988. P.\,331--338.

\bibitem{B_Bouganim96}
{\it Bouganim L., Florescu D., Valduriez P.}
Dynamic Load Ba\-lan\-cing in Hierarchical Parallel
Database Systems // VLDB'96, Proceedings of 22th International Conference on Very Large
Data Bases, September 3-6, 1996, Mumbai (Bombay), India. Morgan Kaufmann. 1996.
P.\,436--447.

\bibitem{B_Chen91}
{\it Chen S., Towsley D.F.}
Performance of a Mirrored Disk in a Real-Time Transaction System // 1991 ACM
SIGMETRICS Conference on Measurement and Modeling of Computer Sys\-tems, San
Diego, California, USA, May 21-24, 1991, Pro\-cee\-dings. Performance Evaluation
Review. May 1991. Vol.\,19, No.\,1.  P.\,198--207.

\bibitem{B_Foster03}
{\it Foster I.T., Grossman R.L.}
Blueprint for the future of high-performance networking: Data integration in a
bandwidth-rich world // Communications of the ACM. 2003. Vol.\,46, No.11. P.\,50--57.

\bibitem{B_GarMol00}
{\it Garcia-Molina H., Ullman J.D., Widom J.}
Database System Implementation. Prentice Hall, 2000. 653~p.

\bibitem{B_Graefe93}
{\it Graefe G.}
Query evaluation techniques for large databases // ACM Computing
Surveys. 1993. Vol.~25, No.2. P.\,73--169.

\bibitem{B_Gray05}
{\it Gray J., Liu D., DeWitt D. J., Heber G. } Scientific Data
Management in the Coming Decade // SIGMOD Record. 2005. Vol. 34, No. 4.

\bibitem{B_Lu92}
{\it Lu H., Tan K. L.}
Dynamic and Load-balanced Task-Oriented Datbase Query Processing in Parallel
Systems // Advances in Database Technology --- EDBT'92, 3rd Int. Conf. on
Extending Database Technology, Vienna, Austria, March 23-27, 1992, Proceedings.
Lect. Not. in Comp. Sc., Vol. 580. Springer. 1992. P.~357--372.

\bibitem{B_Mehta97}
{\it Mehta M., DeWitt D.J.}
Placement in Shared-Nothing Parallel Database Systems // The VLDB Journal.
--- 1997. Vol.~6, No.~1. P.~53--72.

\bibitem{B_Omiecinsky91}
{\it Omiecinski E.}
Performance Analysis of a Load Balancing Hash-Join Algorithm for a Shared
Memory Multiprocessor // 17th International Conference on Very Large Data
Bases, September 3-6, 1991, Barcelona, Catalonia, Spain, Proceedings. Morgan
Kaufmann. 1991. P.~375--385.

\bibitem{B_Williams98}
{\it Williams M.H., Zhou S.}
Data Placement in Parallel Database Systems // Parallel database techniques
/ IEEE Computer society. 1998. P.~203--218.

\bibitem{B_Xu97}
{\it Xu Y., Dandamudi S.P.}
Performance Evaluation of a Two-Level Hierarchical Parallel
Database System // Proceedings of the Int. Conf. Computers and Their Applications, Tempe,
Arizona. 1997. P.~242--247.

\bibitem{B_DeWitt95}
{\it Девитт Д., Грэй Д.}
Параллельные системы баз данных: будущее высоко эффективных систем баз данных%
\,//СУБД. --- М.: Открытые системы, 1995. №2. С.~8---31.

\bibitem{B_Knuth1}
{\it Кнут Д.Э.}
Искусство программирования. Т. 1. Основные алгоритмы, 3-е изд. --- М.:
Изд. дом ``Вильямс'', 2000. 720~с.

\bibitem{B_Knuth3}
{\it Кнут Д.Э.}
Искусство программирования. Т. 3. Сортировка и поиск, 2-е изд. --- М.:
Изд. дом ``Вильямс'', 2000. 832~с.

\bibitem{B_Proto}
Прототип параллельной СУБД Омега

http://omega.susu.ru/prototype/.

\bibitem{B_Sok01}
{\it Соколинский Л.Б.}
Организация параллельного выполнения запросов в многопроцессорной машине баз
данных с иерархической архитектурой\ //\ Программирование.\ --- М.: Наука, 2001. №6. С.~13--29.

\bibitem{B_Sok04}
{\it Соколинский Л.Б.}
Обзор архитектур параллельных систем баз данных //\ Программирование.
--- М.: Наука, 2004. №6. C.~49--63.
\bibitem{B_Cluster}
Технические\hfil характеристики\hfil вычислительного\hfil кластера%

\mbox{Южно-Уральского
государственного университета}

http://cluster.susu.ru/information.

\end{ltrtr}

\thispagestyle{empty}




\end{document}
